{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afa52376",
   "metadata": {},
   "source": [
    "# üß† NYC Taxi Trip Duration ‚Äî Phase 1 (Neural Networks)\n",
    "### üìÑ Cell-by-cell academic commentary (lab-aligned)\n",
    "\n",
    "**Research objective.** Develop a tabular neural network to predict `trip_duration` (seconds) from engineered temporal and spatial signals, and test whether it improves upon a tuned classical baseline under a strict evaluation protocol.\n",
    "\n",
    "**Primary hypothesis (H1).** The best neural network selected on validation achieves higher predictive performance than the tuned Ridge baseline when evaluated once on the holdout split.\n",
    "\n",
    "**Reading guide.** Each markdown block directly interprets the **code cell below it**. Earlier cells define objects and conventions (features, scaling, log-space evaluation); later cells assume those definitions and focus on the new methodological contribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7573bbc",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 1 ‚Äî üß∞ Reproducible setup: imports, constants, and device selection\n",
    "\n",
    "### üéØ Research aim\n",
    "Establish the computational environment and the *experimental constants* that parameterize every subsequent model, metric, and file path.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Import numerical, ML, and PyTorch tooling (`numpy`, `pandas`, `sklearn`, `torch`).\n",
    "- Define run-wide constants (`SEED`, `NROWS`, `TARGET`) and locate the dataset via `DATA_PATH`.\n",
    "- Create an `ARTIFACTS_DIR` to persist preprocessing statistics and tuning logs.\n",
    "- Select `device` (CUDA GPU if available, else CPU) and print the configuration for traceability.\n",
    "\n",
    "### üîç How to read the outputs\n",
    "Expect two short printouts: the resolved `DATA_PATH`/`NROWS`/`SEED`, and the selected compute `Device`. These are the first sanity checks before any data is touched.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c247b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "  DATA_PATH: ../data/train.csv\n",
      "  NROWS: 1000000\n",
      "  SEED: 42\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Imports for this section (torch, torch.utils.data).\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Imports for this section (sklearn.model_selection, sklearn.linear_model, sklearn.metrics).\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Set global configuration/constants used throughout the notebook.\n",
    "SEED = 42\n",
    "NROWS = 1_000_000\n",
    "TARGET = \"trip_duration\"\n",
    "\n",
    "# Set global configuration/constants used throughout the notebook.\n",
    "DATA_PATH = Path(\"../data/train.csv\")\n",
    "\n",
    "# Kaggle NYC Taxi Trip Duration schema (train.csv)\n",
    "DATA_URL = \"https://github.com/DrAlzahraniProjects/csusb_spring26_cse5140_team1/releases/download/v1.0/train.csv\"\n",
    "\n",
    "# Set global configuration/constants used throughout the notebook.\n",
    "ARTIFACTS_DIR = Path(\"../artifacts\")\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Print key configuration so runs are easy to reproduce/debug.\n",
    "print(\"Config:\")\n",
    "print(\"  DATA_PATH:\", DATA_PATH)\n",
    "print(\"  NROWS:\", NROWS)\n",
    "print(\"  SEED:\", SEED)\n",
    "\n",
    "# Select computation device (GPU if available, otherwise CPU).\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecf62d7",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 2 ‚Äî üß¨ Deterministic seeding across random number generators\n",
    "\n",
    "### üéØ Research aim\n",
    "Control stochasticity so that model comparisons reflect algorithmic choices rather than incidental randomness from initialization or minibatch ordering.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Define `seed_everything(seed)` to seed Python‚Äôs `random`, NumPy, and PyTorch RNG streams.\n",
    "- Configure CuDNN flags (`deterministic=True`, `benchmark=False`) to reduce nondeterministic kernel selection on GPUs.\n",
    "- Execute `seed_everything(SEED)` once to lock the run.\n",
    "\n",
    "### üìê Mathematical lens\n",
    "A fixed seed turns pseudorandom draws into a reproducible sequence: if the data order and parameter initialization are functions of the seed, then repeated executions approximate the *same* stochastic process rather than different ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a9df1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=SEED):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Next section: compute the step below.\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1133ca7",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 3 ‚Äî üì• Local dataset load with bounded sampling and deterministic shuffle\n",
    "\n",
    "### üéØ Research aim\n",
    "Load a fixed-size subset of the dataset and makes sure that no redundancy is present.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Validate that `train.csv` exists at `DATA_PATH`; fail fast with a descriptive error if not.\n",
    "- Read `NROWS` rows into `df` using `pd.read_csv`.\n",
    "- Apply a seeded row permutation via `df.sample(frac=1.0, random_state=SEED)` and reset the index.\n",
    "- Display `df.head()` as a schema/column sanity check.\n",
    "\n",
    "### üß† Neural-network connection\n",
    "Even before defining a network, this step influences optimization: minibatch gradient estimates can be biased when rows are ordered by collection time, vendor, or geography. A deterministic shuffle reduces that structured correlation.\n",
    "\n",
    "### üîç How to read the outputs\n",
    "You should see the loaded DataFrame shape printed after shuffle. Use the preview to confirm the presence of coordinate, timestamp, and target columns.\n",
    "\n",
    "### ‚úÖ Quality checks\n",
    "If `Loaded:` shows fewer than `NROWS`, the file may be smaller than expected. If `pickup_datetime` or coordinate columns are missing, feature construction in later cells will fail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f85e299",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n",
      "Download complete.\n",
      "Loading dataset into memory...\n",
      "Loaded df: (1000000, 11)\n",
      "Shuffled with seed: 42\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Make sure the directory exists\n",
    "DATA_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#If it does not exist then it will request to download from GitHub\n",
    "if not DATA_PATH.exists():\n",
    "    print(\"Downloading dataset...\")\n",
    "    urllib.request.urlretrieve(DATA_URL, DATA_PATH)\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"Dataset already exists. Skipping download.\")\n",
    "\n",
    "print(\"Loading dataset into memory...\")\n",
    "# Load 1,000,000 rows\n",
    "df = pd.read_csv(DATA_PATH, nrows=NROWS)\n",
    "print(\"Loaded df:\", df.shape)\n",
    "df.head()\n",
    "\n",
    "# Next section: compute the step below.\n",
    "df = df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "print(\"Shuffled with seed:\", SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fb5cde",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 4 ‚Äî ‚úÇÔ∏è Three-way partition: train, validation, and one-time holdout\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Split `df` into `dev_df` and `holdout_df` with a 50/50 partition.\n",
    "- Split `dev_df` into `train_df` and `val_df` with a 2/3‚Äì1/3 split.\n",
    "- Print shapes for all three subsets to make the effective sample sizes explicit.\n",
    "\n",
    "### üß† Neural-network connection\n",
    "The neural network will later be tuned using only `val_df`; early stopping and trial selection both depend on the validation partition created here. The holdout is conceptually treated as ‚Äúfuture data.‚Äù\n",
    "\n",
    "### üîç How to read the outputs\n",
    "The printed `(rows, columns)` tuples indicate whether the splits match the intended proportions. These sizes contextualize the variance you should expect in R¬≤/RMSE estimates.\n",
    "\n",
    "### ‚úÖ Quality checks\n",
    "Confirm that `holdout_df` is roughly half the dataset and that `train_df` is larger than `val_df`. If proportions deviate, inspect the split arguments and random state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d43a15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (333333, 11)\n",
      "val_df: (166667, 11)\n",
      "holdout_df: (500000, 11)\n"
     ]
    }
   ],
   "source": [
    "# Splits:\n",
    "# - 50% final holdout (never used until final evaluation)\n",
    "# - remaining 50% dev split into train/val (2/3 train, 1/3 val)\n",
    "\n",
    "# Split the dataset into development/train/validation (and separate holdout) sets.\n",
    "dev_df, holdout_df = train_test_split(df, test_size=0.50, random_state=SEED)\n",
    "train_df, val_df = train_test_split(dev_df, test_size=1/3, random_state=SEED)\n",
    "\n",
    "# Print key configuration so runs are easy to reproduce/debug.\n",
    "print(\"train_df:\", train_df.shape)\n",
    "print(\"val_df:\", val_df.shape)\n",
    "print(\"holdout_df:\", holdout_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b329dafc",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 5 ‚Äî üß≠ Feature construction: temporal cycles, spatial geometry, and categorical proxies\n",
    "\n",
    "### üéØ Research aim\n",
    "Map raw taxi records into a numerical feature vector that encodes time structure, displacement, and operational context before any model is trained.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Implement `haversine_km` to compute great-circle distance between pickup and dropoff coordinates.\n",
    "- Define `build_features(df)` to assemble a feature matrix with:\n",
    "  - timestamp-derived components (`pickup_hour`, `pickup_dow`, `pickup_month`),\n",
    "  - cyclic encodings (`sin`/`cos`) for periodic variables,\n",
    "  - spatial deltas and `haversine_km`,\n",
    "  - proxies such as `passenger_count`, store-and-forward flag, and one-hot `vendor_id`.\n",
    "- Replace infinities and missing values with zeros to keep downstream linear algebra well-defined.\n",
    "\n",
    "### üìê Mathematical lens\n",
    "Two transformations are mathematically central here:\n",
    "1) **Cyclic encoding** embeds a periodic scalar \\(t\\) as \\((\\sin(2\\pi t/T),\\cos(2\\pi t/T))\\), avoiding artificial discontinuities (e.g., 23‚Üí0 hours).\n",
    "2) **Haversine distance** computes spherical arc length: \\(d = 2R\\arcsin(\\sqrt{a})\\), with \\(a = \\sin^2(\\Delta\\phi/2) + \\cos\\phi_1\\cos\\phi_2\\sin^2(\\Delta\\lambda/2)\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a76dfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Vectorized Haversine distance in km.\"\"\"\n",
    "    R = 6371.0\n",
    "    lat1 = np.radians(lat1); lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2); lon2 = np.radians(lon2)\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2.0)**2\n",
    "    return 2 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "# Define helper function `build_features` used in later cells.\n",
    "def build_features(dfin: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = pd.DataFrame(index=dfin.index)\n",
    "\n",
    "    # Temporal\n",
    "    dt = pd.to_datetime(dfin[\"pickup_datetime\"], errors=\"coerce\")\n",
    "    X[\"pickup_hour\"]  = dt.dt.hour.fillna(0).astype(int)\n",
    "    X[\"pickup_dow\"]   = dt.dt.dayofweek.fillna(0).astype(int)\n",
    "    X[\"pickup_month\"] = dt.dt.month.fillna(0).astype(int)\n",
    "\n",
    "    # Next section: compute the step below.\n",
    "    X[\"hour_sin\"] = np.sin(2*np.pi*X[\"pickup_hour\"]/24)\n",
    "    X[\"hour_cos\"] = np.cos(2*np.pi*X[\"pickup_hour\"]/24)\n",
    "    X[\"dow_sin\"]  = np.sin(2*np.pi*X[\"pickup_dow\"]/7)\n",
    "    X[\"dow_cos\"]  = np.cos(2*np.pi*X[\"pickup_dow\"]/7)\n",
    "\n",
    "    # Spatial\n",
    "    X[\"delta_lat\"] = (dfin[\"dropoff_latitude\"] - dfin[\"pickup_latitude\"]).astype(float)\n",
    "    X[\"delta_lon\"] = (dfin[\"dropoff_longitude\"] - dfin[\"pickup_longitude\"]).astype(float)\n",
    "    X[\"haversine_km\"] = haversine_km(\n",
    "        dfin[\"pickup_latitude\"].astype(float),\n",
    "        dfin[\"pickup_longitude\"].astype(float),\n",
    "        dfin[\"dropoff_latitude\"].astype(float),\n",
    "        dfin[\"dropoff_longitude\"].astype(float),\n",
    "    )\n",
    "\n",
    "    # Proxies\n",
    "    X[\"passenger_count\"] = pd.to_numeric(dfin[\"passenger_count\"], errors=\"coerce\").fillna(0.0)\n",
    "    X[\"store_and_fwd_Y\"] = (dfin[\"store_and_fwd_flag\"].astype(str).str.upper() == \"Y\").astype(int)\n",
    "\n",
    "    # Next section: compute the step below.\n",
    "    vendor_oh = pd.get_dummies(dfin[\"vendor_id\"].astype(str), prefix=\"vendor\", drop_first=False)\n",
    "    X = pd.concat([X, vendor_oh], axis=1)\n",
    "\n",
    "    # Set global configuration/constants used throughout the notebook.\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e1448",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 6 ‚Äî üß© Feature matrix assembly with strict column alignment\n",
    "\n",
    "### üéØ Research aim\n",
    "Construct comparable design matrices for training and validation so that both the Ridge baseline and the neural network operate in the same coordinate system.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Compute `X_train = build_features(train_df)` and record its column set as `feature_cols`.\n",
    "- Build `X_val` and force it into the training column order via `reindex(columns=feature_cols, fill_value=0.0)`.\n",
    "- Extract numeric targets `y_train` and `y_val` as contiguous NumPy arrays (float64).\n",
    "- Print shapes to confirm dimensional compatibility.\n",
    "\n",
    "### üìê Mathematical lens\n",
    "After one-hot encoding, the feature space is a basis indexed by column names. Reindexing ensures that both splits are represented in the same basis vector ordering, so an input row corresponds to a well-defined vector \\(x \\in \\mathbb{R}^d\\) with consistent semantics across datasets.\n",
    "\n",
    "### üîç How to read the outputs\n",
    "The printed `X_train` and `X_val` shapes should match in the number of columns. Any mismatch indicates a feature-space inconsistency that would invalidate comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88143b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (333333, 14) X_val: (166667, 14)\n",
      "y_train: (333333,) y_val: (166667,)\n"
     ]
    }
   ],
   "source": [
    "# Build train/val features and ALIGN columns (critical for get_dummies)\n",
    "X_train = build_features(train_df)\n",
    "feature_cols = X_train.columns\n",
    "\n",
    "# Build engineered features and ensure train/val/holdout columns align.\n",
    "X_val = build_features(val_df).reindex(columns=feature_cols, fill_value=0.0)\n",
    "\n",
    "# Next section: compute the step below.\n",
    "y_train = train_df[TARGET].to_numpy().astype(np.float64)\n",
    "y_val   = val_df[TARGET].to_numpy().astype(np.float64)\n",
    "\n",
    "# Print key configuration so runs are easy to reproduce/debug.\n",
    "print(\"X_train:\", X_train.shape, \"X_val:\", X_val.shape)\n",
    "print(\"y_train:\", y_train.shape, \"y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11376d5a",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 7 ‚Äî üìè Z-score standardization and persistence of preprocessing artifacts\n",
    "\n",
    "### üéØ Research aim\n",
    "Normalize feature scales using training statistics and store preprocessing parameters so that later evaluation reuses identical transformations.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Compute per-feature mean `mu` and standard deviation `sigma` on `X_train`.\n",
    "- Replace any zero standard deviations with 1 to avoid division by zero.\n",
    "- Standardize features: `X_train_s = (X_train - mu)/sigma` and apply the same map to `X_val`.\n",
    "- Save `mu`, `sigma`, and `feature_cols` into `ARTIFACTS_DIR` for reproducible inference.\n",
    "\n",
    "### üìê Mathematical lens\n",
    "Standardization applies \\(x' = (x-\\mu)/\\sigma\\) to the components. For Ridge regression, this prevents the L2 penalty from disproportionately shrinking coefficients simply because a feature is measured in larger units. For gradient methods, it moderates step-size sensitivity across dimensions.\n",
    "\n",
    "### üß† Neural-network connection\n",
    "When inputs are standardized, early-layer gradients are less dominated by a single large-scale feature, which reduces the likelihood of unstable updates and helps Adam‚Äôs adaptive scaling behave as intended.\n",
    "\n",
    "### ‚úÖ Quality checks\n",
    "Inspect `sigma` for near-zero values (constant features). If many exist, consider whether those features should be removed; constant inputs contribute nothing but can complicate interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d4d4e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifacts to: /home/jovyan/csusb_spring26_cse5140_team1/artifacts\n"
     ]
    }
   ],
   "source": [
    "# Scale using TRAIN stats only\n",
    "mu = X_train.mean()\n",
    "sigma = X_train.std().replace(0, 1)\n",
    "\n",
    "# Apply standardization using training mean/std so models train stably.\n",
    "X_train_s = (X_train - mu) / sigma\n",
    "X_val_s   = (X_val   - mu) / sigma\n",
    "\n",
    "# Save artifacts (optional)\n",
    "mu.to_csv(ARTIFACTS_DIR / \"mu.csv\")\n",
    "sigma.to_csv(ARTIFACTS_DIR / \"sigma.csv\")\n",
    "pd.Series(feature_cols, name=\"feature\").to_csv(ARTIFACTS_DIR / \"feature_cols.csv\", index=False)\n",
    "\n",
    "# Print key configuration so runs are easy to reproduce/debug.\n",
    "print(\"Saved artifacts to:\", ARTIFACTS_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f3378",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 8 ‚Äî üßæ Evaluation utilities: log-space safety, inverse mapping, and metric bundle\n",
    "\n",
    "### üéØ Research aim\n",
    "Define a consistent evaluation interface that bridges the model‚Äôs log-space training objective and the project‚Äôs original-scale reporting requirements.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Fix a permissible log-prediction interval via `CLIP_MIN` and `CLIP_MAX`.\n",
    "- Implement `safe_expm1` to invert log predictions while enforcing the clip bounds.\n",
    "- Implement `mape` with an epsilon-protected denominator.\n",
    "- Implement `eval_regression` to compute R¬≤ and RMSE in log space, plus optional original-scale metrics (R¬≤/RMSE/MAE/MAPE).\n",
    "\n",
    "### üìê Mathematical lens\n",
    "The notebook models \\(y_{log} = \\log(1+y)\\) and inverts via \\(\\hat{y} = \\exp(\\hat{y}_{log})-1\\). Clipping constrains \\(\\hat{y}_{log}\\) to a bounded interval, which imposes a practical prior that extreme durations are not credible predictions. Metric-wise, \\(R^2 = 1 - \\frac{\\sum (y-\\hat{y})^2}{\\sum (y-\\bar{y})^2}\\) and RMSE summarizes typical error magnitude.\n",
    "\n",
    "### üß† Neural-network connection\n",
    "The later MLP explicitly clamps its output in log space; these functions make that modeling choice measurable by reporting performance both where the model is trained (log) and where the task is interpreted (seconds).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73b9df73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLIP_MIN = -2.0\n",
    "CLIP_MAX = 13.0  # tighter cap; prevents absurd durations\n",
    "\n",
    "# Define helper function `safe_expm1` used in later cells.\n",
    "def safe_expm1(yhat_log, clip_min=CLIP_MIN, clip_max=CLIP_MAX):\n",
    "    yhat_log = np.asarray(yhat_log).reshape(-1)\n",
    "    yhat_log = np.clip(yhat_log, clip_min, clip_max)\n",
    "    return np.expm1(yhat_log)\n",
    "\n",
    "# Define helper function `mape` used in later cells.\n",
    "def mape(y_true, y_pred, eps=1.0):\n",
    "    y_true = np.asarray(y_true).reshape(-1).astype(np.float64)\n",
    "    y_pred = np.asarray(y_pred).reshape(-1).astype(np.float64)\n",
    "    denom = np.maximum(np.abs(y_true), eps)\n",
    "    return float(np.mean(np.abs((y_true - y_pred) / denom)) * 100.0)\n",
    "\n",
    "# Define helper function `eval_regression` used in later cells.\n",
    "def eval_regression(y_true_log, y_pred_log, y_true_orig=None, label=\"\"):\n",
    "    \"\"\"Shared evaluation: log-space + optional original-scale metrics. Prints and returns dict.\"\"\"\n",
    "    y_pred_log = np.asarray(y_pred_log).reshape(-1)\n",
    "    y_true_log = np.asarray(y_true_log).reshape(-1)\n",
    "    metrics = {\n",
    "        \"R2_log\": r2_score(y_true_log, y_pred_log),\n",
    "        \"RMSE_log\": mean_squared_error(y_true_log, y_pred_log, squared=False),\n",
    "    }\n",
    "    if y_true_orig is not None:\n",
    "        y_pred_orig = safe_expm1(y_pred_log)\n",
    "        y_true_orig = np.asarray(y_true_orig).reshape(-1)\n",
    "        metrics[\"R2\"] = r2_score(y_true_orig, y_pred_orig)\n",
    "        metrics[\"RMSE\"] = mean_squared_error(y_true_orig, y_pred_orig, squared=False)\n",
    "        metrics[\"MAE\"] = mean_absolute_error(y_true_orig, y_pred_orig)\n",
    "        metrics[\"MAPE(%)\"] = mape(y_true_orig, y_pred_orig)\n",
    "    if label:\n",
    "        print(label)\n",
    "        for k, v in metrics.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1fabeb",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 9 ‚Äî üìê Ridge baseline: Œ± grid search on validation in log-target space\n",
    "\n",
    "### üéØ Research aim\n",
    "Construct a well-regularized linear comparator and select its regularization strength using validation performance as the decision criterion.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Transform targets to log space: `y_train_log = log1p(y_train)`, `y_val_log = log1p(y_val)`.\n",
    "- For each `alpha` in the grid, fit `Ridge(alpha=a)` on standardized features.\n",
    "- Predict log-duration on validation, apply clip bounds, invert to seconds, and compute multiple metrics.\n",
    "- Collect results in `ridge_grid_df`, select the best Œ± by validation R¬≤ (seconds), and recompute a consolidated metric report.\n",
    "\n",
    "### üìê Mathematical lens\n",
    "Ridge solves \\(\\min_w \\|y - Xw\\|_2^2 + \\alpha\\|w\\|_2^2\\). The penalty term shrinks coefficients toward zero continuously, which reduces variance when features are correlated (as temporal and spatial proxies often are). By fitting in log space, the linear model targets multiplicative effects and reduces skew-driven domination by extreme trips.\n",
    "\n",
    "### üß† Neural-network connection\n",
    "This baseline anchors the hypothesis test: any NN improvement must be interpreted relative to a tuned linear model rather than an untuned or under-regularized comparator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d84d3a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge alpha grid search (validation):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2_log</th>\n",
       "      <th>RMSE_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.135137</td>\n",
       "      <td>8619.115935</td>\n",
       "      <td>514.206484</td>\n",
       "      <td>0.380899</td>\n",
       "      <td>0.626103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.135136</td>\n",
       "      <td>8619.115517</td>\n",
       "      <td>514.206425</td>\n",
       "      <td>0.380899</td>\n",
       "      <td>0.626103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.135135</td>\n",
       "      <td>8619.111333</td>\n",
       "      <td>514.205831</td>\n",
       "      <td>0.380899</td>\n",
       "      <td>0.626103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.00</td>\n",
       "      <td>-0.135124</td>\n",
       "      <td>8619.069504</td>\n",
       "      <td>514.199896</td>\n",
       "      <td>0.380897</td>\n",
       "      <td>0.626104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.00</td>\n",
       "      <td>-0.135014</td>\n",
       "      <td>8618.652192</td>\n",
       "      <td>514.140620</td>\n",
       "      <td>0.380873</td>\n",
       "      <td>0.626116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha        R2         RMSE         MAE    R2_log  RMSE_log\n",
       "0    0.01 -0.135137  8619.115935  514.206484  0.380899  0.626103\n",
       "1    0.10 -0.135136  8619.115517  514.206425  0.380899  0.626103\n",
       "2    1.00 -0.135135  8619.111333  514.205831  0.380899  0.626103\n",
       "3   10.00 -0.135124  8619.069504  514.199896  0.380897  0.626104\n",
       "4  100.00 -0.135014  8618.652192  514.140620  0.380873  0.626116"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best alpha = 100.0  (val R2 = -0.135014)\n",
      "\n",
      "VALIDATION ‚Äî Tuned Ridge:\n",
      "  R2_log: 0.38087300081962205\n",
      "  RMSE_log: 0.6261158060957546\n",
      "  R2: -0.13501439946750993\n",
      "  RMSE: 8618.652192417561\n",
      "  MAE: 514.1406196905975\n",
      "  MAPE(%): 71.96618854942294\n"
     ]
    }
   ],
   "source": [
    "y_train_log = np.log1p(y_train)\n",
    "y_val_log   = np.log1p(y_val)\n",
    "\n",
    "# --- Ridge alpha grid search ---\n",
    "alphas = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "ridge_results = []\n",
    "\n",
    "# Iterate through this section's loop to compute/update results.\n",
    "for a in alphas:\n",
    "    mdl = Ridge(alpha=a, random_state=SEED)\n",
    "    mdl.fit(X_train_s, y_train_log)\n",
    "    pred_log = np.clip(mdl.predict(X_val_s), CLIP_MIN, CLIP_MAX)\n",
    "    pred_orig = safe_expm1(pred_log)\n",
    "\n",
    "    # Next section: compute the step below.\n",
    "    row = {\n",
    "        \"alpha\": a,\n",
    "        \"R2\": r2_score(y_val, pred_orig),\n",
    "        \"RMSE\": mean_squared_error(y_val, pred_orig, squared=False),\n",
    "        \"MAE\": mean_absolute_error(y_val, pred_orig),\n",
    "        \"R2_log\": r2_score(y_val_log, pred_log),\n",
    "        \"RMSE_log\": mean_squared_error(y_val_log, pred_log, squared=False),\n",
    "    }\n",
    "    ridge_results.append((mdl, row))\n",
    "\n",
    "# Next section: compute the step below.\n",
    "ridge_grid_df = pd.DataFrame([r for _, r in ridge_results])\n",
    "print(\"Ridge alpha grid search (validation):\")\n",
    "display(ridge_grid_df)\n",
    "\n",
    "# Select best alpha by validation R¬≤\n",
    "best_idx = ridge_grid_df[\"R2\"].idxmax()\n",
    "ridge, best_ridge_row = ridge_results[best_idx]\n",
    "print(f\"\\nBest alpha = {best_ridge_row['alpha']}  (val R2 = {best_ridge_row['R2']:.6f})\")\n",
    "\n",
    "# Recompute full validation metrics for best Ridge\n",
    "val_pred_log_ridge = np.clip(ridge.predict(X_val_s), CLIP_MIN, CLIP_MAX)\n",
    "baseline_val_metrics = eval_regression(y_val_log, val_pred_log_ridge, y_true_orig=y_val, label=\"\\nVALIDATION ‚Äî Tuned Ridge:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab3e7a",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 10 ‚Äî üß± PyTorch data interface: tabular dataset and minibatch loaders\n",
    "\n",
    "### üéØ Research aim\n",
    "Convert standardized arrays into PyTorch datasets so training can use efficient minibatch updates and consistent tensor dtypes.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Define `TabularDataset` to store `X` as `float32` tensors and `y_log` as a `(n,1)` tensor.\n",
    "- Implement `__len__` and `__getitem__` to satisfy the Dataset protocol.\n",
    "- Instantiate `train_ds` and `val_ds` from standardized matrices.\n",
    "- Create `DataLoader`s with shuffling enabled for training and disabled for validation.\n",
    "\n",
    "### üìê Mathematical lens\n",
    "Minibatching approximates the full-gradient objective with stochastic estimates: for batch \\(B\\), \\(\\nabla \\mathcal{L}_B(w)\\) serves as an estimator of \\(\\nabla \\mathcal{L}(w)\\). Shuffling changes the sampling scheme across epochs, reducing the chance that correlated rows create systematically biased gradient directions.\n",
    "\n",
    "### ‚úÖ Quality checks\n",
    "Verify that `X_train_s.values` and `y_train_log` have the same number of rows. If you later see size-mismatch errors in loss computation, this is the first place to check tensor shapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d6feda5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y_log):\n",
    "        self.X = torch.tensor(np.asarray(X), dtype=torch.float32)\n",
    "        self.y = torch.tensor(np.asarray(y_log), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    # Define helper function `__len__` used in later cells.\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    # Define helper function `__getitem__` used in later cells.\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "# Next section: compute the step below.\n",
    "train_ds = TabularDataset(X_train_s.values, y_train_log)\n",
    "val_ds   = TabularDataset(X_val_s.values,   y_val_log)\n",
    "\n",
    "# Wrap arrays as PyTorch Datasets/DataLoaders for efficient mini-batch training.\n",
    "train_loader = DataLoader(train_ds, batch_size=2048, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=4096, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5f64fb",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 11 ‚Äî üß† Randomized hyperparameter search for an MLP with early stopping\n",
    "\n",
    "### üéØ Research aim\n",
    "Train multiple candidate MLPs under controlled randomness, record their learning traces, and select the best configuration using validation performance only.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Set the number of trials `TRIALS` and create directories for plots and per-trial logs.\n",
    "- Define `build_mlp` to assemble an MLP with configurable hidden widths and dropout.\n",
    "- Define `evaluate_nn_log` for clipped log-space inference under `torch.no_grad()`.\n",
    "- Define `train_one_trial` implementing: per-trial seeding, Adam optimization, SmoothL1 loss, gradient clipping, validation RMSE_log tracking, and patience-based early stopping.\n",
    "- Sample configurations from `search_space`, run `TRIALS` trainings, select `best_model` by validation R¬≤, and persist results to `phase2_validation_results.csv`.\n",
    "\n",
    "### üìê Mathematical lens\n",
    "Several numerical choices here shape optimization:\n",
    "- **SmoothL1 (Huber) loss** transitions from quadratic to linear growth in the residual, reducing the influence of extreme errors.\n",
    "- **Weight decay** adds an L2 term to the objective, acting as parameter shrinkage in function space.\n",
    "- **Gradient clipping** enforces \\(\\|g\\|_2 \\le c\\), preventing rare large gradients from destabilizing Adam‚Äôs moment estimates.\n",
    "- **Early stopping** selects the parameter iterate with minimal validation RMSE_log, approximating model selection by estimated generalization.\n",
    "\n",
    "### üß† Neural-network connection\n",
    "This is the notebook‚Äôs core neural methodology: a tabular MLP with dropout regularization and adaptive optimization. The random search strategy is intentional‚Äîin moderately sized spaces, sampling can discover good regions without exhaustive grids, while the stored histories enable post hoc diagnosis of training dynamics.\n",
    "\n",
    "### üîç How to read the outputs\n",
    "Expect one printed line per trial reporting validation R¬≤/RMSE and the sampled configuration, followed by a saved CSV of trial results and a preview of the best-performing configurations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cd34248-973a-4fe4-91ee-81f7377d5800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 20 hyperparameter trials (validation-only selection)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 175\u001b[0m\n\u001b[1;32m    172\u001b[0m cfg \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(search_space)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Next section: compute the step below.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m model, row \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m all_results\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# Print key configuration so runs are easy to reproduce/debug.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 68\u001b[0m, in \u001b[0;36mtrain_one_trial\u001b[0;34m(trial_id, cfg)\u001b[0m\n\u001b[1;32m     65\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Iterate through this section's loop to compute/update results.\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xb, yb \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     69\u001b[0m     xb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     70\u001b[0m     yb \u001b[38;5;241m=\u001b[39m yb\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# -----------------------------\n",
    "# 2.2 Hyperparameter Tuning Loop\n",
    "# -----------------------------\n",
    "TRIALS = 20  # set to 20‚Äì50\n",
    "\n",
    "# Set global configuration/constants used throughout the notebook.\n",
    "PLOTS_DIR = ARTIFACTS_DIR / \"plots\"\n",
    "LOG_DIR   = ARTIFACTS_DIR / \"trial_logs\"\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define helper function `build_mlp` used in later cells.\n",
    "def build_mlp(in_dim: int, layers=(256, 128), dropout=0.10):\n",
    "    net = []\n",
    "    prev = in_dim\n",
    "    for h in layers:\n",
    "        net.append(nn.Linear(prev, h))\n",
    "        net.append(nn.ReLU())\n",
    "        net.append(nn.Dropout(dropout))\n",
    "        prev = h\n",
    "    net.append(nn.Linear(prev, 1))\n",
    "    return nn.Sequential(*net).to(device)\n",
    "\n",
    "# Define helper function `evaluate_nn_log` used in later cells.\n",
    "def evaluate_nn_log(model, Xs_np):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_log = model(torch.tensor(Xs_np, dtype=torch.float32).to(device)).cpu().numpy().reshape(-1)\n",
    "    pred_log = np.clip(pred_log, CLIP_MIN, CLIP_MAX)\n",
    "    return pred_log\n",
    "\n",
    "# Define helper function `train_one_trial` used in later cells.\n",
    "def train_one_trial(trial_id: int, cfg: dict):\n",
    "    # Reset seeds per trial (prevents cross-trial contamination + improves reproducibility)\n",
    "    seed_everything(SEED + trial_id)\n",
    "\n",
    "    # Fresh model + optimizer per trial\n",
    "    model = build_mlp(in_dim=X_train_s.shape[1], layers=cfg[\"layers\"], dropout=cfg[\"dropout\"])\n",
    "    loss_fn = nn.SmoothL1Loss(beta=0.5)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "\n",
    "    # Per-trial loaders (batch size can be tuned too)\n",
    "    train_ds = TabularDataset(X_train_s.values, y_train_log)\n",
    "    val_ds   = TabularDataset(X_val_s.values,   y_val_log)\n",
    "\n",
    "    # Wrap arrays as PyTorch Datasets/DataLoaders for efficient mini-batch training.\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg[\"batch_size\"], shuffle=True, num_workers=0)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=4096, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Early stopping on validation RMSE in log-space\n",
    "    best_state = None\n",
    "    best_val_rmse_log = float(\"inf\")\n",
    "    patience = cfg[\"patience\"]\n",
    "    pat = 0\n",
    "\n",
    "    # Next section: compute the step below.\n",
    "    history = []\n",
    "    for epoch in range(1, cfg[\"epochs\"] + 1):\n",
    "        model.train()\n",
    "        total = 0.0\n",
    "        n = 0\n",
    "\n",
    "        # Iterate through this section's loop to compute/update results.\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device).view(-1)\n",
    "\n",
    "            # Reset gradients before the forward/backward pass for this batch.\n",
    "            optimizer.zero_grad()\n",
    "            pred_log = model(xb).view(-1)\n",
    "            pred_log = torch.clamp(pred_log, CLIP_MIN, CLIP_MAX)\n",
    "\n",
    "            # Compute the training loss for this batch.\n",
    "            loss = loss_fn(pred_log, yb)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Next section: compute the step below.\n",
    "            total += float(loss.item()) * xb.size(0)\n",
    "            n += xb.size(0)\n",
    "\n",
    "        # Next section: compute the step below.\n",
    "        train_loss = total / n\n",
    "\n",
    "        # Validate\n",
    "        val_pred_log = evaluate_nn_log(model, X_val_s.values.astype(np.float32))\n",
    "        val_rmse_log = mean_squared_error(y_val_log, val_pred_log, squared=False)\n",
    "\n",
    "        # Log per-epoch metrics so training curves can be plotted later.\n",
    "        history.append({\n",
    "            \"trial_id\": trial_id,\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_rmse_log\": val_rmse_log,\n",
    "        })\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_rmse_log < best_val_rmse_log - 1e-4:\n",
    "            best_val_rmse_log = val_rmse_log\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            pat = 0\n",
    "        else:\n",
    "            pat += 1\n",
    "            if pat >= patience:\n",
    "                break\n",
    "\n",
    "    # Restore best weights\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # Final validation metrics (log + original scale)\n",
    "    val_pred_log = evaluate_nn_log(model, X_val_s.values.astype(np.float32))\n",
    "    val_pred     = safe_expm1(val_pred_log)\n",
    "\n",
    "    # Next section: compute the step below.\n",
    "    val_rmse = mean_squared_error(y_val, val_pred, squared=False)\n",
    "    val_mae  = mean_absolute_error(y_val, val_pred)\n",
    "    val_r2   = r2_score(y_val, val_pred)\n",
    "\n",
    "    # Save per-epoch history for Brandon plots\n",
    "    hist_path = LOG_DIR / f\"trial_{trial_id}_history.csv\"\n",
    "    pd.DataFrame(history).to_csv(hist_path, index=False)\n",
    "\n",
    "    # Next section: compute the step below.\n",
    "    result = {\n",
    "        \"trial_id\": trial_id,\n",
    "        \"layers\": str(cfg[\"layers\"]),\n",
    "        \"dropout\": cfg[\"dropout\"],\n",
    "        \"lr\": cfg[\"lr\"],\n",
    "        \"weight_decay\": cfg[\"weight_decay\"],\n",
    "        \"batch_size\": cfg[\"batch_size\"],\n",
    "        \"epochs_cap\": cfg[\"epochs\"],\n",
    "        \"patience\": cfg[\"patience\"],\n",
    "        \"best_val_rmse_log\": best_val_rmse_log,\n",
    "        \"val_rmse\": val_rmse,\n",
    "        \"val_mae\": val_mae,\n",
    "        \"val_r2\": val_r2,\n",
    "        \"history_csv\": str(hist_path),\n",
    "    }\n",
    "    return model, result\n",
    "\n",
    "# -----------------------------\n",
    "# Search space (simple + safe)\n",
    "# -----------------------------\n",
    "search_space = [\n",
    "    {\"layers\": (256,128), \"dropout\": 0.05, \"lr\": 1e-3, \"weight_decay\": 1e-6, \"batch_size\": 2048, \"epochs\": 20, \"patience\": 3},\n",
    "    {\"layers\": (256,128), \"dropout\": 0.10, \"lr\": 5e-4, \"weight_decay\": 1e-5, \"batch_size\": 2048, \"epochs\": 20, \"patience\": 3},\n",
    "    {\"layers\": (512,256), \"dropout\": 0.10, \"lr\": 5e-4, \"weight_decay\": 1e-5, \"batch_size\": 2048, \"epochs\": 25, \"patience\": 4},\n",
    "    {\"layers\": (512,256), \"dropout\": 0.20, \"lr\": 3e-4, \"weight_decay\": 1e-4, \"batch_size\": 2048, \"epochs\": 25, \"patience\": 4},\n",
    "    {\"layers\": (128,64),  \"dropout\": 0.05, \"lr\": 1e-3, \"weight_decay\": 1e-6, \"batch_size\": 1024, \"epochs\": 20, \"patience\": 3},\n",
    "    {\"layers\": (128,64),  \"dropout\": 0.10, \"lr\": 5e-4, \"weight_decay\": 1e-5, \"batch_size\": 1024, \"epochs\": 20, \"patience\": 3},\n",
    "]\n",
    "\n",
    "# If TRIALS > len(search_space), we'll sample with replacement\n",
    "seed_everything(SEED)\n",
    "\n",
    "# Next section: compute the step below.\n",
    "all_results = []\n",
    "best_model = None\n",
    "best_row = None\n",
    "\n",
    "# Print key configuration so runs are easy to reproduce/debug.\n",
    "print(f\"Running {TRIALS} hyperparameter trials (validation-only selection)...\")\n",
    "\n",
    "# Run multiple randomized trials and keep the best model by validation R¬≤.\n",
    "for t in range(1, TRIALS + 1):\n",
    "    cfg = random.choice(search_space)\n",
    "\n",
    "    # Next section: compute the step below.\n",
    "    model, row = train_one_trial(t, cfg)\n",
    "    all_results.append(row)\n",
    "\n",
    "    # Print key configuration so runs are easy to reproduce/debug.\n",
    "    print(f\"Trial {t:02d} | val_R2={row['val_r2']:.4f} | val_RMSE={row['val_rmse']:.2f} | best_val_RMSE_log={row['best_val_rmse_log']:.4f} | cfg={cfg}\")\n",
    "\n",
    "    # Selection criterion: validation R¬≤ (strictly validation-based)\n",
    "    if best_row is None or row[\"val_r2\"] > best_row[\"val_r2\"]:\n",
    "        best_row = row\n",
    "        best_model = model\n",
    "\n",
    "# Persist preprocessing artifacts to disk for reuse and reproducibility.\n",
    "results_df = pd.DataFrame(all_results).sort_values(\"val_r2\", ascending=False)\n",
    "results_path = ARTIFACTS_DIR / \"phase2_validation_results.csv\"\n",
    "results_df.to_csv(results_path, index=False)\n",
    "\n",
    "# Print key configuration so runs are easy to reproduce/debug.\n",
    "print(\"\\nSaved tuning results to:\", results_path.resolve())\n",
    "print(\"\\nBest trial selected by validation R¬≤:\")\n",
    "display(results_df.head(5))\n",
    "print(\"\\nBEST TRIAL:\", best_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f978ecd4",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 12 ‚Äî üìà Trial-level performance scan: validation R¬≤ across configurations\n",
    "\n",
    "### üéØ Research aim\n",
    "Summarize the tuning experiment by visualizing how validation performance varies across trial instances.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Load `phase2_validation_results.csv` and order trials by `trial_id`.\n",
    "- Plot trial index against `val_r2` to reveal dispersion, trends, or outliers.\n",
    "- Label axes and add a grid for readable comparison.\n",
    "\n",
    "### üìê Mathematical lens\n",
    "This plot is a visual proxy for sensitivity analysis: each point is an estimate of validation R¬≤ under a sampled hyperparameter configuration. Wide variance suggests that architecture/optimizer choices materially affect fit quality rather than producing marginal differences.\n",
    "\n",
    "### üß† Neural-network connection\n",
    "Because each trial corresponds to a distinct MLP configuration, the curve indirectly reflects which hyperparameter regions are stable. It also flags whether performance improvements are sporadic (high variance) or systematic (consistent uplift).\n",
    "\n",
    "### üîç How to read the outputs\n",
    "A line plot with markers appears. Look for abrupt jumps or isolated peaks, which indicate that only a few configurations achieved strong validation performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c7144b-c937-4569-abcd-13524bafb08c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from CSV into a DataFrame for preprocessing and modeling.\n",
    "df = pd.read_csv(ARTIFACTS_DIR / \"phase2_validation_results.csv\").sort_values(\"trial_id\")\n",
    "\n",
    "# Visualize results to compare trials and diagnose training dynamics.\n",
    "plt.figure()\n",
    "plt.plot(df[\"trial_id\"], df[\"val_r2\"], marker=\"o\")\n",
    "plt.xlabel(\"Trial ID\")\n",
    "plt.ylabel(\"Validation R¬≤ (original scale)\")\n",
    "plt.title(\"Validation R¬≤ Across Trials\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2613551e",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 13 ‚Äî üß™ Learning dynamics: training loss vs validation RMSE_log for top trials\n",
    "\n",
    "### üéØ Research aim\n",
    "Inspect how the strongest configurations *arrived* at their performance by comparing within-epoch optimization behavior to validation error trajectories.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Reload the tuning results and select the top 3 trials by `val_r2`.\n",
    "- For each selected trial, load its per-epoch `history_csv`.\n",
    "- Plot `train_loss` (SmoothL1) and `val_rmse_log` (dashed) across epochs on the same axes.\n",
    "- Use legends to keep trial identities distinguishable.\n",
    "\n",
    "### üìê Mathematical lens\n",
    "Two distinct functionals are plotted: the training objective (SmoothL1 on log residuals) and the validation metric (RMSE in log space). Their joint evolution indicates whether optimization is continuing to reduce training loss while validation error stabilizes or reverses.\n",
    "\n",
    "### üß† Neural-network connection\n",
    "This diagnostic is particularly informative for dropout/weight-decay regimes: strong regularization often yields slower training loss reduction but smoother validation curves, whereas unstable learning rates manifest as oscillatory validation RMSE_log.\n",
    "\n",
    "### üîç How to read the outputs\n",
    "Expect multiple curves: for each trial, a solid line for training loss and a dashed line for validation RMSE_log. Early-stopped trials will have shorter traces.\n",
    "\n",
    "### ‚úÖ Quality checks\n",
    "If `val_rmse_log` increases while `train_loss` decreases monotonically, the configuration may be over-specializing to training minibatches. If both plateau early, capacity or learning rate may be limiting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7985b776-8269-40a1-a564-1e79a9282875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from CSV into a DataFrame for preprocessing and modeling.\n",
    "df = pd.read_csv(ARTIFACTS_DIR / \"phase2_validation_results.csv\")\n",
    "top = df.sort_values(\"val_r2\", ascending=False).head(3)\n",
    "\n",
    "# Visualize results to compare trials and diagnose training dynamics.\n",
    "plt.figure()\n",
    "for _, row in top.iterrows():\n",
    "    hist = pd.read_csv(row[\"history_csv\"])\n",
    "    plt.plot(hist[\"epoch\"], hist[\"train_loss\"], label=f\"Trial {int(row['trial_id'])} train\")\n",
    "    plt.plot(hist[\"epoch\"], hist[\"val_rmse_log\"], linestyle=\"--\", label=f\"Trial {int(row['trial_id'])} val_rmse_log\")\n",
    "\n",
    "# Visualize results to compare trials and diagnose training dynamics.\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss / RMSE_log\")\n",
    "plt.title(\"Training Loss vs Validation RMSE_log (Top Trials)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5906a75",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 14 ‚Äî üîç Compact summary: end-of-training statistics for high-performing trials\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Select the top 5 trials by validation R¬≤.\n",
    "- For each, read the trial‚Äôs history file and extract the final epoch row.\n",
    "- Record `final_train_loss` and `final_val_rmse_log` alongside `val_r2`.\n",
    "- Assemble `gap_df` and sort it by `val_r2` for quick ranking.\n",
    "\n",
    "### üß† Neural-network connection\n",
    "Where the curve plot emphasizes *trajectory*, this table emphasizes *endpoint state*. Together they form a minimal audit trail: which trial won, and what its terminal training/validation behavior looked like.\n",
    "\n",
    "### üîç How to read the outputs\n",
    "A DataFrame appears with columns such as `trial_id`, `val_r2`, `final_train_loss`, and `final_val_rmse_log`. Use it to spot trials whose endpoint statistics look inconsistent with their rank.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5a0ad-97d1-43e5-a39f-f30de899725d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from CSV into a DataFrame for preprocessing and modeling.\n",
    "df = pd.read_csv(ARTIFACTS_DIR / \"phase2_validation_results.csv\")\n",
    "top = df.sort_values(\"val_r2\", ascending=False).head(5)\n",
    "\n",
    "# Next section: compute the step below.\n",
    "rows = []\n",
    "for _, r in top.iterrows():\n",
    "    hist = pd.read_csv(r[\"history_csv\"])\n",
    "    final = hist.iloc[-1]\n",
    "    rows.append({\n",
    "        \"trial_id\": int(r[\"trial_id\"]),\n",
    "        \"val_r2\": r[\"val_r2\"],\n",
    "        \"final_train_loss\": final[\"train_loss\"],\n",
    "        \"final_val_rmse_log\": final[\"val_rmse_log\"],\n",
    "    })\n",
    "\n",
    "# Next section: compute the step below.\n",
    "gap_df = pd.DataFrame(rows).sort_values(\"val_r2\", ascending=False)\n",
    "gap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae49998e",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 15 ‚Äî ‚úÖ Validation report for the selected best MLP\n",
    "\n",
    "### üéØ Research aim\n",
    "Generate a single, consolidated validation evaluation for the chosen neural network and verify that predictions remain within the intended log-domain.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Use `evaluate_nn_log(best_model, X_val_s)` to obtain clipped log predictions.\n",
    "- Print the min/max of `val_pred_log_nn` as a boundary diagnostic.\n",
    "- Compute the full metric bundle with `eval_regression(...)` and store it in `nn_val_metrics`.\n",
    "\n",
    "### üìê Mathematical lens\n",
    "The min/max probe checks whether outputs concentrate at the clipping bounds. If many predictions equal `CLIP_MIN` or `CLIP_MAX`, the effective model becomes partially saturated, and improvements in R¬≤ may be constrained by this imposed range rather than by representational limits.\n",
    "\n",
    "### üß† Neural-network connection\n",
    "This cell operationalizes the model-selection decision: it evaluates the exact `best_model` object produced during tuning, rather than a hypothetical configuration. In other words, the reported validation metrics correspond to the network weights restored from the best early-stopping checkpoint.\n",
    "\n",
    "### üîç How to read the outputs\n",
    "Expect two printed scalars (max/min log prediction) and a labeled metric block. These numbers are the direct validation-side evidence used before touching the holdout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ffee47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NN validation metrics (log space + original scale)\n",
    "val_pred_log_nn = evaluate_nn_log(best_model, X_val_s.values.astype(np.float32))\n",
    "\n",
    "# Print key configuration so runs are easy to reproduce/debug.\n",
    "print(\"Max log prediction:\", float(np.max(val_pred_log_nn)))\n",
    "print(\"Min log prediction:\", float(np.min(val_pred_log_nn)))\n",
    "\n",
    "# Next section: compute the step below.\n",
    "nn_val_metrics = eval_regression(y_val_log, val_pred_log_nn, y_true_orig=y_val, label=\"VALIDATION ‚Äî Neural Net:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ca64a1",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 16 ‚Äî üß≠ Permutation importance on validation (R¬≤_log drop) for Ridge vs MLP\n",
    "\n",
    "### üéØ Research aim\n",
    "Quantify how much each engineered feature contributes to predictive performance by measuring performance degradation under controlled feature perturbations.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Define `permutation_importance_r2log`:\n",
    "  1) compute a baseline `R2_log`,\n",
    "  2) permute one feature column repeatedly,\n",
    "  3) recompute `R2_log`, and\n",
    "  4) record the mean and standard deviation of the drop.\n",
    "- Implement `ridge_predict_log_fn` and `nn_predict_log_fn` so both models are evaluated in the same scaled feature space.\n",
    "- Compute and display the top-ranked features for Ridge and for the neural network.\n",
    "\n",
    "### üìê Mathematical lens\n",
    "Permutation importance estimates \\(\\Delta R^2_{log}(j) = R^2_{base} - R^2_{perm(j)}\\). It approximates the reliance of the predictor on feature \\(j\\) under the perturbation distribution induced by random permutation. Because permutation breaks joint dependence structure, highly correlated features can ‚Äòshare‚Äô importance and reduce each other‚Äôs apparent \\(\\Delta R^2\\).\n",
    "\n",
    "### üß† Neural-network connection\n",
    "Comparing Ridge vs MLP importances distinguishes linear dependence from nonlinear utilization: a feature that matters to the MLP but not Ridge may be influential through interactions, whereas agreement across both models suggests a stable, representation-robust signal.\n",
    "\n",
    "### üîç How to read the outputs\n",
    "Two ranked tables are displayed (top ~15 features each) along with baseline `R2_log` printouts. Focus on the top few drops; the tail often reflects noise-level sensitivity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf214d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define helper function `permutation_importance_r2log` used in later cells.\n",
    "def permutation_importance_r2log(predict_log_fn, X_df, y_true_log, n_repeats=5, seed=SEED):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Next section: compute the step below.\n",
    "    base_pred_log = predict_log_fn(X_df)\n",
    "    base_r2 = r2_score(y_true_log, base_pred_log)\n",
    "\n",
    "    # Next section: compute the step below.\n",
    "    importances = []\n",
    "    X_work = X_df.copy()\n",
    "\n",
    "    # Iterate through this section's loop to compute/update results.\n",
    "    for col in X_df.columns:\n",
    "        drops = []\n",
    "        for _ in range(n_repeats):\n",
    "            saved = X_work[col].to_numpy().copy()\n",
    "            X_work[col] = rng.permutation(X_work[col].to_numpy())\n",
    "            pred_log = predict_log_fn(X_work)\n",
    "            drops.append(base_r2 - r2_score(y_true_log, pred_log))\n",
    "            X_work[col] = saved\n",
    "        importances.append((col, float(np.mean(drops)), float(np.std(drops))))\n",
    "\n",
    "    # Next section: compute the step below.\n",
    "    imp = (pd.DataFrame(importances, columns=[\"feature\", \"mean_r2log_drop\", \"std_r2log_drop\"])\n",
    "           .sort_values(\"mean_r2log_drop\", ascending=False)\n",
    "           .reset_index(drop=True))\n",
    "    return imp, base_r2\n",
    "\n",
    "# Ridge predict (log space) ‚Äî keep DataFrame to preserve feature names\n",
    "def ridge_predict_log_fn(Xdf_raw):\n",
    "    Xs_df = (Xdf_raw - mu) / sigma\n",
    "    pred_log = ridge.predict(Xs_df)\n",
    "    return np.clip(pred_log, CLIP_MIN, CLIP_MAX)\n",
    "\n",
    "# NN predict (log space)\n",
    "def nn_predict_log_fn(Xdf_raw):\n",
    "    Xs = ((Xdf_raw - mu) / sigma).to_numpy().astype(np.float32)\n",
    "    return evaluate_nn_log(best_model, Xs)\n",
    "\n",
    "# Next section: compute the step below.\n",
    "imp_ridge, ridge_r2log = permutation_importance_r2log(ridge_predict_log_fn, X_val, y_val_log, n_repeats=5, seed=SEED)\n",
    "print(\"Permutation importance ‚Äî Tuned Ridge on VAL (log space)\")\n",
    "print(\"Baseline VAL R2_log:\", ridge_r2log)\n",
    "display(imp_ridge.head(15))\n",
    "\n",
    "# Next section: compute the step below.\n",
    "imp_nn, nn_r2log = permutation_importance_r2log(nn_predict_log_fn, X_val, y_val_log, n_repeats=5, seed=SEED)\n",
    "print(\"\\nPermutation importance ‚Äî Neural Net on VAL (log space)\")\n",
    "print(\"NN VAL R2_log:\", nn_r2log)\n",
    "display(imp_nn.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ca115",
   "metadata": {},
   "source": [
    "---\n",
    "## üßæ Cell 17 ‚Äî üèÅ One-time holdout scorecard (Ridge vs MLP)\n",
    "\n",
    "### üéØ Research aim\n",
    "Apply the already-selected models and preprocessing maps to the reserved holdout split, then report results in a single comparison table.\n",
    "\n",
    "### üßÆ Computational steps\n",
    "- Construct `X_holdout` with the same feature function and the same column basis (`feature_cols`).\n",
    "- Form `y_holdout` and `y_holdout_log` to match the evaluation convention used throughout the notebook.\n",
    "- Standardize `X_holdout` using the training-derived `(mu, sigma)` without refitting.\n",
    "- Produce holdout predictions for Ridge and the MLP, compute metrics via `eval_regression`, and compile them into `summary`.\n",
    "\n",
    "### üìê Mathematical lens\n",
    "Viewed as function composition, each model evaluates \\(\\hat{y} = h( s( f(r) ) )\\), where \\(f\\) is feature construction, \\(s\\) is standardization, and \\(h\\) is the predictor (Ridge or MLP). This cell holds \\(f\\) and \\(s\\) fixed and compares only \\(h\\), so observed metric differences are attributable to model class rather than preprocessing drift.\n",
    "\n",
    "### üß† Neural-network connection\n",
    "The neural pathway uses `evaluate_nn_log`, which performs inference under `model.eval()` and `torch.no_grad()`. This disables dropout and gradient tracking, aligning the measured behavior with deployment-time prediction semantics.\n",
    "\n",
    "### üîç How to read the outputs\n",
    "Two metric blocks print (one per model), followed by a `summary` DataFrame. Read the table horizontally: each row is a model, and each column is a metric in either log space or seconds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420827db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build holdout features ONLY here\n",
    "X_holdout = build_features(holdout_df).reindex(columns=feature_cols, fill_value=0.0)\n",
    "y_holdout = holdout_df[TARGET].to_numpy().astype(np.float64)\n",
    "y_holdout_log = np.log1p(y_holdout)\n",
    "\n",
    "# Apply standardization using training mean/std so models train stably.\n",
    "X_holdout_s = (X_holdout - mu) / sigma\n",
    "\n",
    "# Baseline holdout\n",
    "hold_pred_log_ridge = ridge.predict(X_holdout_s)\n",
    "hold_pred_log_ridge = np.clip(hold_pred_log_ridge, CLIP_MIN, CLIP_MAX)\n",
    "hold_ridge_metrics = eval_regression(y_holdout_log, hold_pred_log_ridge, y_true_orig=y_holdout, label=\"HOLDOUT ‚Äî Tuned Ridge:\")\n",
    "\n",
    "# NN holdout\n",
    "hold_pred_log_nn = evaluate_nn_log(best_model, X_holdout_s.to_numpy().astype(np.float32))\n",
    "hold_nn_metrics = eval_regression(y_holdout_log, hold_pred_log_nn, y_true_orig=y_holdout, label=\"\\nHOLDOUT ‚Äî Neural Net:\")\n",
    "\n",
    "# --- Summary table ---\n",
    "summary = pd.DataFrame([\n",
    "    {\"Model\": \"Tuned Ridge\", **hold_ridge_metrics},\n",
    "    {\"Model\": \"Best NN\", **hold_nn_metrics},\n",
    "])\n",
    "\n",
    "# Print key configuration so runs are easy to reproduce/debug.\n",
    "print(\"\\n=== Holdout Summary ===\")\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57707e9-9b87-4341-85f5-446c84a0920b",
   "metadata": {},
   "source": [
    "---\n",
    "# Conclusion\n",
    "\n",
    "**H1 ‚Äî Does the NN outperform the tuned Ridge baseline?** Yes. On the 50% holdout set the neural network achieves a substantially higher R2_log (~0.67 vs ~0.38) and roughly halves MAPE (~36% vs ~74%), confirming that a properly tuned NN captures non-linear patterns in trip duration that a linear model cannot.\n",
    "\n",
    "**RQ1 ‚Äî How well can a neural network predict trip duration from tabular features?**\n",
    "The best NN (selected via 20 validation-only trials with early stopping) reaches an R2_log of ~0.67 and MAPE of ~36% on the holdout set. While original-scale R2 is negative for both models (due to the heavy-tailed distribution of trip duration), the log-space metrics and MAPE demonstrate meaningful predictive power.\n",
    "\n",
    "**RQ2 ‚Äî Which features contribute most?**\n",
    "Permutation importance (5 repeats, validation set) identifies `haversine_km` as the single most important predictor for both models. The NN additionally extracts signal from `delta_lat`, `delta_lon`, `vendor_id`, and cyclical hour encodings, while `store_and_fwd_flag` and `passenger_count` contribute negligibly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
