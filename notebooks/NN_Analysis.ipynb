{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9df5c2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NYC Taxi Trip Duration — Phase 1 (Neural Networks)\n",
    "\n",
    "This notebook satisfies **Phase 1: Neural Networks (NN)** deliverables:\n",
    "\n",
    "- **RQ1:** How well can a neural network predict trip duration from tabular features?\n",
    "- **RQ2:** Which features contribute most to predictive performance?\n",
    "- **H1:** A properly tuned neural network will outperform a classical baseline (e.g., Ridge regression).\n",
    "\n",
    "**Important evaluation note (heavy‑tailed target):**\n",
    "Trip duration is heavy‑tailed. We train on `log1p(trip_duration)` and report:\n",
    "- **Log-space metrics** (recommended for model selection): **R²_log**, **RMSE_log**\n",
    "- **Original-scale metrics** (interpretability): **RMSE**, **MAE**, **MAPE**, **R²**\n",
    "- For the “normalized” comparison requested by the rubric: **R²_log + MAPE** on holdout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c247b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "  DATA_PATH: ../data/train.csv\n",
      "  NROWS: 1000000\n",
      "  SEED: 42\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "SEED = 42\n",
    "NROWS = 1_000_000\n",
    "TARGET = \"trip_duration\"\n",
    "\n",
    "# Kaggle NYC Taxi Trip Duration schema (train.csv)\n",
    "DATA_URL = \"https://github.com/DrAlzahraniProjects/csusb_spring26_cse5140_team1/releases/download/v1.0/train.csv\"\n",
    "DATA_PATH = Path(\"../data/train.csv\")\n",
    "\n",
    "ARTIFACTS_DIR = Path(\"../artifacts\")\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Config:\")\n",
    "print(\"  DATA_PATH:\", DATA_PATH)\n",
    "print(\"  NROWS:\", NROWS)\n",
    "print(\"  SEED:\", SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f815c361-ba7c-4e02-aaa6-d2f627333155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists. Skipping download.\n",
      "Loading dataset into memory...\n",
      "Loaded df: (1000000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id2875421</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-14 17:24:55</td>\n",
       "      <td>2016-03-14 17:32:30</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982155</td>\n",
       "      <td>40.767937</td>\n",
       "      <td>-73.964630</td>\n",
       "      <td>40.765602</td>\n",
       "      <td>N</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2377394</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-12 00:43:35</td>\n",
       "      <td>2016-06-12 00:54:38</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.980415</td>\n",
       "      <td>40.738564</td>\n",
       "      <td>-73.999481</td>\n",
       "      <td>40.731152</td>\n",
       "      <td>N</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3858529</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-19 11:35:24</td>\n",
       "      <td>2016-01-19 12:10:48</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.979027</td>\n",
       "      <td>40.763939</td>\n",
       "      <td>-74.005333</td>\n",
       "      <td>40.710087</td>\n",
       "      <td>N</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3504673</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-06 19:32:31</td>\n",
       "      <td>2016-04-06 19:39:40</td>\n",
       "      <td>1</td>\n",
       "      <td>-74.010040</td>\n",
       "      <td>40.719971</td>\n",
       "      <td>-74.012268</td>\n",
       "      <td>40.706718</td>\n",
       "      <td>N</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id2181028</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-26 13:30:55</td>\n",
       "      <td>2016-03-26 13:38:10</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.973053</td>\n",
       "      <td>40.793209</td>\n",
       "      <td>-73.972923</td>\n",
       "      <td>40.782520</td>\n",
       "      <td>N</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id      pickup_datetime     dropoff_datetime   \n",
       "0  id2875421          2  2016-03-14 17:24:55  2016-03-14 17:32:30  \\\n",
       "1  id2377394          1  2016-06-12 00:43:35  2016-06-12 00:54:38   \n",
       "2  id3858529          2  2016-01-19 11:35:24  2016-01-19 12:10:48   \n",
       "3  id3504673          2  2016-04-06 19:32:31  2016-04-06 19:39:40   \n",
       "4  id2181028          2  2016-03-26 13:30:55  2016-03-26 13:38:10   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude   \n",
       "0                1        -73.982155        40.767937         -73.964630  \\\n",
       "1                1        -73.980415        40.738564         -73.999481   \n",
       "2                1        -73.979027        40.763939         -74.005333   \n",
       "3                1        -74.010040        40.719971         -74.012268   \n",
       "4                1        -73.973053        40.793209         -73.972923   \n",
       "\n",
       "   dropoff_latitude store_and_fwd_flag  trip_duration  \n",
       "0         40.765602                  N            455  \n",
       "1         40.731152                  N            663  \n",
       "2         40.710087                  N           2124  \n",
       "3         40.706718                  N            429  \n",
       "4         40.782520                  N            435  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Make sure the directory exists\n",
    "DATA_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    print(\"Downloading dataset...\")\n",
    "    urllib.request.urlretrieve(DATA_URL, DATA_PATH)\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"Dataset already exists. Skipping download.\")\n",
    "\n",
    "print(\"Loading dataset into memory...\")\n",
    "df = pd.read_csv(DATA_PATH, nrows=NROWS)\n",
    "print(\"Loaded df:\", df.shape)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35a9df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=SEED):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f85e299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (1000000, 11)\n",
      "Shuffled with seed: 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id3435429</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-18 22:34:53</td>\n",
       "      <td>2016-02-18 22:49:37</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.956161</td>\n",
       "      <td>40.694500</td>\n",
       "      <td>-73.987869</td>\n",
       "      <td>40.720985</td>\n",
       "      <td>N</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id2267606</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-14 14:37:43</td>\n",
       "      <td>2016-05-14 14:52:09</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.975922</td>\n",
       "      <td>40.757133</td>\n",
       "      <td>-73.950813</td>\n",
       "      <td>40.770882</td>\n",
       "      <td>N</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id3771460</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-15 01:42:25</td>\n",
       "      <td>2016-06-15 01:52:02</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982391</td>\n",
       "      <td>40.762222</td>\n",
       "      <td>-73.952019</td>\n",
       "      <td>40.777706</td>\n",
       "      <td>N</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id2766058</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-21 22:37:26</td>\n",
       "      <td>2016-03-21 22:42:10</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.998482</td>\n",
       "      <td>40.740463</td>\n",
       "      <td>-74.004646</td>\n",
       "      <td>40.722782</td>\n",
       "      <td>N</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id2834780</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-07 21:33:57</td>\n",
       "      <td>2016-06-07 21:36:06</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.998169</td>\n",
       "      <td>40.735550</td>\n",
       "      <td>-73.991913</td>\n",
       "      <td>40.744041</td>\n",
       "      <td>N</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id      pickup_datetime     dropoff_datetime   \n",
       "0  id3435429          1  2016-02-18 22:34:53  2016-02-18 22:49:37  \\\n",
       "1  id2267606          1  2016-05-14 14:37:43  2016-05-14 14:52:09   \n",
       "2  id3771460          1  2016-06-15 01:42:25  2016-06-15 01:52:02   \n",
       "3  id2766058          2  2016-03-21 22:37:26  2016-03-21 22:42:10   \n",
       "4  id2834780          2  2016-06-07 21:33:57  2016-06-07 21:36:06   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude   \n",
       "0                1        -73.956161        40.694500         -73.987869  \\\n",
       "1                1        -73.975922        40.757133         -73.950813   \n",
       "2                1        -73.982391        40.762222         -73.952019   \n",
       "3                2        -73.998482        40.740463         -74.004646   \n",
       "4                1        -73.998169        40.735550         -73.991913   \n",
       "\n",
       "   dropoff_latitude store_and_fwd_flag  trip_duration  \n",
       "0         40.720985                  N            884  \n",
       "1         40.770882                  N            866  \n",
       "2         40.777706                  N            577  \n",
       "3         40.722782                  N            284  \n",
       "4         40.744041                  N            129  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load 1,000,000 rows and shuffle deterministically\n",
    "df = pd.read_csv(DATA_PATH, nrows=NROWS)\n",
    "print(\"Loaded:\", df.shape)\n",
    "\n",
    "df = df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "print(\"Shuffled with seed:\", SEED)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d43a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (333333, 11)\n",
      "val_df: (166667, 11)\n",
      "holdout_df: (500000, 11)\n"
     ]
    }
   ],
   "source": [
    "# Splits:\n",
    "# - 50% final holdout (never used until final evaluation)\n",
    "# - remaining 50% dev split into train/val (2/3 train, 1/3 val)\n",
    "\n",
    "dev_df, holdout_df = train_test_split(df, test_size=0.50, random_state=SEED)\n",
    "train_df, val_df = train_test_split(dev_df, test_size=1/3, random_state=SEED)\n",
    "\n",
    "print(\"train_df:\", train_df.shape)\n",
    "print(\"val_df:\", val_df.shape)\n",
    "print(\"holdout_df:\", holdout_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8f3c31",
   "metadata": {},
   "source": [
    "## Feature families (temporal + spatial/distance + proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a76dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Vectorized Haversine distance in km.\"\"\"\n",
    "    R = 6371.0\n",
    "    lat1 = np.radians(lat1); lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2); lon2 = np.radians(lon2)\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2.0)**2\n",
    "    return 2 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "def build_features(dfin: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = pd.DataFrame(index=dfin.index)\n",
    "\n",
    "    # Temporal\n",
    "    dt = pd.to_datetime(dfin[\"pickup_datetime\"], errors=\"coerce\")\n",
    "    X[\"pickup_hour\"]  = dt.dt.hour.fillna(0).astype(int)\n",
    "    X[\"pickup_dow\"]   = dt.dt.dayofweek.fillna(0).astype(int)\n",
    "    X[\"pickup_month\"] = dt.dt.month.fillna(0).astype(int)\n",
    "\n",
    "    X[\"hour_sin\"] = np.sin(2*np.pi*X[\"pickup_hour\"]/24)\n",
    "    X[\"hour_cos\"] = np.cos(2*np.pi*X[\"pickup_hour\"]/24)\n",
    "    X[\"dow_sin\"]  = np.sin(2*np.pi*X[\"pickup_dow\"]/7)\n",
    "    X[\"dow_cos\"]  = np.cos(2*np.pi*X[\"pickup_dow\"]/7)\n",
    "\n",
    "    # Spatial\n",
    "    X[\"delta_lat\"] = (dfin[\"dropoff_latitude\"] - dfin[\"pickup_latitude\"]).astype(float)\n",
    "    X[\"delta_lon\"] = (dfin[\"dropoff_longitude\"] - dfin[\"pickup_longitude\"]).astype(float)\n",
    "    X[\"haversine_km\"] = haversine_km(\n",
    "        dfin[\"pickup_latitude\"].astype(float),\n",
    "        dfin[\"pickup_longitude\"].astype(float),\n",
    "        dfin[\"dropoff_latitude\"].astype(float),\n",
    "        dfin[\"dropoff_longitude\"].astype(float),\n",
    "    )\n",
    "\n",
    "    # Proxies\n",
    "    X[\"passenger_count\"] = pd.to_numeric(dfin[\"passenger_count\"], errors=\"coerce\").fillna(0.0)\n",
    "    X[\"store_and_fwd_Y\"] = (dfin[\"store_and_fwd_flag\"].astype(str).str.upper() == \"Y\").astype(int)\n",
    "\n",
    "    vendor_oh = pd.get_dummies(dfin[\"vendor_id\"].astype(str), prefix=\"vendor\", drop_first=False)\n",
    "    X = pd.concat([X, vendor_oh], axis=1)\n",
    "\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88143b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (333333, 14) X_val: (166667, 14)\n",
      "y_train: (333333,) y_val: (166667,)\n"
     ]
    }
   ],
   "source": [
    "# Build train/val features and ALIGN columns (critical for get_dummies)\n",
    "X_train = build_features(train_df)\n",
    "feature_cols = X_train.columns\n",
    "\n",
    "X_val = build_features(val_df).reindex(columns=feature_cols, fill_value=0.0)\n",
    "\n",
    "y_train = train_df[TARGET].to_numpy().astype(np.float64)\n",
    "y_val   = val_df[TARGET].to_numpy().astype(np.float64)\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"X_val:\", X_val.shape)\n",
    "print(\"y_train:\", y_train.shape, \"y_val:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d4d4e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifacts to: /home/jovyan/csusb_spring26_cse5140_team1/artifacts\n"
     ]
    }
   ],
   "source": [
    "# Scale using TRAIN stats only\n",
    "mu = X_train.mean()\n",
    "sigma = X_train.std().replace(0, 1)\n",
    "\n",
    "X_train_s = (X_train - mu) / sigma\n",
    "X_val_s   = (X_val   - mu) / sigma\n",
    "\n",
    "# Save artifacts (optional)\n",
    "mu.to_csv(ARTIFACTS_DIR / \"mu.csv\")\n",
    "sigma.to_csv(ARTIFACTS_DIR / \"sigma.csv\")\n",
    "pd.Series(feature_cols, name=\"feature\").to_csv(ARTIFACTS_DIR / \"feature_cols.csv\", index=False)\n",
    "\n",
    "print(\"Saved artifacts to:\", ARTIFACTS_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b065a8",
   "metadata": {},
   "source": [
    "## Metrics helpers (log space + original scale)\n",
    "We select/tune models using **log-space** metrics (R²_log, RMSE_log) and report **MAPE** for normalized comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b9df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIP_MIN = -2.0\n",
    "CLIP_MAX = 13.0  # tighter cap; prevents absurd durations\n",
    "\n",
    "def safe_expm1(yhat_log, clip_min=CLIP_MIN, clip_max=CLIP_MAX):\n",
    "    yhat_log = np.asarray(yhat_log).reshape(-1)\n",
    "    yhat_log = np.clip(yhat_log, clip_min, clip_max)\n",
    "    return np.expm1(yhat_log)\n",
    "\n",
    "def mape(y_true, y_pred, eps=1.0):\n",
    "    y_true = np.asarray(y_true).reshape(-1).astype(np.float64)\n",
    "    y_pred = np.asarray(y_pred).reshape(-1).astype(np.float64)\n",
    "    denom = np.maximum(np.abs(y_true), eps)\n",
    "    return float(np.mean(np.abs((y_true - y_pred) / denom)) * 100.0)\n",
    "\n",
    "def report_log(y_true_log, y_pred_log, label=\"\"):\n",
    "    rmse_log = mean_squared_error(y_true_log, y_pred_log, squared=False)\n",
    "    r2_log = r2_score(y_true_log, y_pred_log)\n",
    "    print(label)\n",
    "    print(\"  RMSE_log:\", rmse_log)\n",
    "    print(\"  R2_log  :\", r2_log)\n",
    "    return {\"rmse_log\": rmse_log, \"r2_log\": r2_log}\n",
    "\n",
    "def report_orig(y_true, y_pred, label=\"\"):\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    mae_ = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    mape_ = mape(y_true, y_pred)\n",
    "    print(label)\n",
    "    print(\"  RMSE:\", rmse)\n",
    "    print(\"  MAE :\", mae_)\n",
    "    print(\"  R^2 :\", r2)\n",
    "    print(\"  MAPE(%):\", mape_)\n",
    "    return {\"rmse\": rmse, \"mae\": mae_, \"r2\": r2, \"mape\": mape_}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a4ad3f",
   "metadata": {},
   "source": [
    "## Baseline: Ridge regression (trained on log1p target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d84d3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION — Baseline (Ridge) log space:\n",
      "  RMSE_log: 0.6261026872904123\n",
      "  R2_log  : 0.3808989452900038\n",
      "VALIDATION — Baseline (Ridge) original scale:\n",
      "  RMSE: 8619.111333223163\n",
      "  MAE : 514.2058312823963\n",
      "  R^2 : -0.13513533376099418\n",
      "  MAPE(%): 71.96278901754312\n"
     ]
    }
   ],
   "source": [
    "y_train_log = np.log1p(y_train)\n",
    "y_val_log   = np.log1p(y_val)\n",
    "\n",
    "ridge = Ridge(alpha=1.0, random_state=SEED)\n",
    "ridge.fit(X_train_s, y_train_log)\n",
    "\n",
    "val_pred_log_ridge = ridge.predict(X_val_s)\n",
    "val_pred_log_ridge = np.clip(val_pred_log_ridge, CLIP_MIN, CLIP_MAX)\n",
    "\n",
    "val_pred_ridge = safe_expm1(val_pred_log_ridge)\n",
    "\n",
    "baseline_log = report_log(y_val_log, val_pred_log_ridge, \"VALIDATION — Baseline (Ridge) log space:\")\n",
    "baseline_orig = report_orig(y_val, val_pred_ridge, \"VALIDATION — Baseline (Ridge) original scale:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6fd5b9",
   "metadata": {},
   "source": [
    "## Neural Network (PyTorch)\n",
    "Stabilized training: output clamp + SmoothL1Loss + gradient clipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d6feda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y_log):\n",
    "        self.X = torch.tensor(np.asarray(X), dtype=torch.float32)\n",
    "        self.y = torch.tensor(np.asarray(y_log), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "train_ds = TabularDataset(X_train_s.values, y_train_log)\n",
    "val_ds   = TabularDataset(X_val_s.values,   y_val_log)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=2048, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=4096, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1552aff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=14, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.1, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.1, inplace=False)\n",
      "  (6): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "in_dim = X_train_s.shape[1]\n",
    "\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(in_dim, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.10),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.10),\n",
    "    nn.Linear(128, 1),\n",
    ").to(device)\n",
    "\n",
    "loss_fn = nn.SmoothL1Loss(beta=0.5)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "\n",
    "print(mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "203ea0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=1.3420 | val_RMSE_log=0.7132\n",
      "Epoch 02 | train_loss=0.3420 | val_RMSE_log=0.5440\n",
      "Epoch 03 | train_loss=0.2881 | val_RMSE_log=0.5099\n",
      "Epoch 04 | train_loss=0.2689 | val_RMSE_log=0.4968\n",
      "Epoch 05 | train_loss=0.2579 | val_RMSE_log=0.4897\n",
      "Epoch 06 | train_loss=0.2501 | val_RMSE_log=0.4862\n",
      "Epoch 07 | train_loss=0.2441 | val_RMSE_log=0.4816\n",
      "Epoch 08 | train_loss=0.2407 | val_RMSE_log=0.4803\n",
      "Epoch 09 | train_loss=0.2380 | val_RMSE_log=0.4801\n",
      "Epoch 10 | train_loss=0.2344 | val_RMSE_log=0.4756\n",
      "Epoch 11 | train_loss=0.2304 | val_RMSE_log=0.4749\n",
      "Epoch 12 | train_loss=0.2269 | val_RMSE_log=0.4721\n",
      "Best VAL RMSE_log: 0.4720816003370926\n"
     ]
    }
   ],
   "source": [
    "def evaluate_nn_log(model, Xs_np):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_log = model(torch.tensor(Xs_np, dtype=torch.float32).to(device)).cpu().numpy().reshape(-1)\n",
    "    pred_log = np.clip(pred_log, CLIP_MIN, CLIP_MAX)\n",
    "    return pred_log\n",
    "\n",
    "# Train with early stopping on VAL RMSE_log\n",
    "best_state = None\n",
    "best_rmse_log = float(\"inf\")\n",
    "patience = 3\n",
    "pat = 0\n",
    "\n",
    "EPOCHS = 12\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    mlp.train()\n",
    "    total = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device).view(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred_log = mlp(xb).view(-1)\n",
    "        pred_log = torch.clamp(pred_log, CLIP_MIN, CLIP_MAX)  # key stabilization\n",
    "        loss = loss_fn(pred_log, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(mlp.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total += float(loss.item()) * xb.size(0)\n",
    "        n += xb.size(0)\n",
    "\n",
    "    train_loss = total / n\n",
    "\n",
    "    # validation in log space\n",
    "    val_pred_log_nn = evaluate_nn_log(mlp, X_val_s.values.astype(np.float32))\n",
    "    val_rmse_log = mean_squared_error(y_val_log, val_pred_log_nn, squared=False)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | val_RMSE_log={val_rmse_log:.4f}\")\n",
    "\n",
    "    if val_rmse_log < best_rmse_log - 1e-4:\n",
    "        best_rmse_log = val_rmse_log\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in mlp.state_dict().items()}\n",
    "        pat = 0\n",
    "    else:\n",
    "        pat += 1\n",
    "        if pat >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "# Restore best\n",
    "if best_state is not None:\n",
    "    mlp.load_state_dict(best_state)\n",
    "print(\"Best VAL RMSE_log:\", best_rmse_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ffee47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max log prediction: 13.0\n",
      "Min log prediction: 4.476377010345459\n",
      "VALIDATION — Neural Net log space:\n",
      "  RMSE_log: 0.4720816003370926\n",
      "  R2_log  : 0.6480308851436248\n",
      "VALIDATION — Neural Net original scale:\n",
      "  RMSE: 8218.487433101236\n",
      "  MAE : 376.79086097955735\n",
      "  R^2 : -0.03206357847685437\n",
      "  MAPE(%): 37.743075886472475\n"
     ]
    }
   ],
   "source": [
    "# NN validation metrics (log space + original scale)\n",
    "val_pred_log_nn = evaluate_nn_log(mlp, X_val_s.values.astype(np.float32))\n",
    "val_pred_nn = safe_expm1(val_pred_log_nn)\n",
    "\n",
    "print(\"Max log prediction:\", float(np.max(val_pred_log_nn)))\n",
    "print(\"Min log prediction:\", float(np.min(val_pred_log_nn)))\n",
    "\n",
    "nn_log = report_log(y_val_log, val_pred_log_nn, \"VALIDATION — Neural Net log space:\")\n",
    "nn_orig = report_orig(y_val, val_pred_nn, \"VALIDATION — Neural Net original scale:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a92fcb",
   "metadata": {},
   "source": [
    "## Feature importance (Permutation)\n",
    "We compute permutation importance using **drop in R²_log** on validation to avoid heavy‑tail instability on original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ebf214d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation importance — Baseline (Ridge) on VAL (log space)\n",
      "Baseline VAL R2_log: 0.3808989452900038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2log_drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>haversine_km</td>\n",
       "      <td>0.640220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hour_cos</td>\n",
       "      <td>0.024273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hour_sin</td>\n",
       "      <td>0.010955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dow_cos</td>\n",
       "      <td>0.007680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pickup_month</td>\n",
       "      <td>0.003107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>delta_lon</td>\n",
       "      <td>0.002728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dow_sin</td>\n",
       "      <td>0.001783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pickup_dow</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>passenger_count</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pickup_hour</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vendor_1</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vendor_2</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>store_and_fwd_Y</td>\n",
       "      <td>-0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>delta_lat</td>\n",
       "      <td>-0.006482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  r2log_drop\n",
       "0      haversine_km    0.640220\n",
       "1          hour_cos    0.024273\n",
       "2          hour_sin    0.010955\n",
       "3           dow_cos    0.007680\n",
       "4      pickup_month    0.003107\n",
       "5         delta_lon    0.002728\n",
       "6           dow_sin    0.001783\n",
       "7        pickup_dow    0.000992\n",
       "8   passenger_count    0.000311\n",
       "9       pickup_hour    0.000162\n",
       "10         vendor_1    0.000134\n",
       "11         vendor_2    0.000126\n",
       "12  store_and_fwd_Y   -0.000002\n",
       "13        delta_lat   -0.006482"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation importance — Neural Net on VAL (log space)\n",
      "NN VAL R2_log: 0.6480308851436248\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2log_drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vendor_1</td>\n",
       "      <td>1.936115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vendor_2</td>\n",
       "      <td>1.927551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>haversine_km</td>\n",
       "      <td>1.652740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hour_cos</td>\n",
       "      <td>0.624782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pickup_hour</td>\n",
       "      <td>0.265949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dow_cos</td>\n",
       "      <td>0.220403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pickup_dow</td>\n",
       "      <td>0.165449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hour_sin</td>\n",
       "      <td>0.162388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dow_sin</td>\n",
       "      <td>0.158319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>delta_lat</td>\n",
       "      <td>0.140979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>delta_lon</td>\n",
       "      <td>0.030007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>passenger_count</td>\n",
       "      <td>0.004213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pickup_month</td>\n",
       "      <td>0.003219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>store_and_fwd_Y</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  r2log_drop\n",
       "0          vendor_1    1.936115\n",
       "1          vendor_2    1.927551\n",
       "2      haversine_km    1.652740\n",
       "3          hour_cos    0.624782\n",
       "4       pickup_hour    0.265949\n",
       "5           dow_cos    0.220403\n",
       "6        pickup_dow    0.165449\n",
       "7          hour_sin    0.162388\n",
       "8           dow_sin    0.158319\n",
       "9         delta_lat    0.140979\n",
       "10        delta_lon    0.030007\n",
       "11  passenger_count    0.004213\n",
       "12     pickup_month    0.003219\n",
       "13  store_and_fwd_Y    0.000117"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def permutation_importance_r2log(predict_log_fn, X_df, y_true_log, n_repeats=3, seed=SEED):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    base_pred_log = predict_log_fn(X_df)\n",
    "    base_r2 = r2_score(y_true_log, base_pred_log)\n",
    "\n",
    "    importances = []\n",
    "    X_work = X_df.copy()\n",
    "\n",
    "    for col in X_df.columns:\n",
    "        drops = []\n",
    "        for _ in range(n_repeats):\n",
    "            saved = X_work[col].to_numpy().copy()\n",
    "            X_work[col] = rng.permutation(X_work[col].to_numpy())\n",
    "            pred_log = predict_log_fn(X_work)\n",
    "            drops.append(base_r2 - r2_score(y_true_log, pred_log))\n",
    "            X_work[col] = saved\n",
    "        importances.append((col, float(np.mean(drops))))\n",
    "\n",
    "    imp = pd.DataFrame(importances, columns=[\"feature\", \"r2log_drop\"]).sort_values(\"r2log_drop\", ascending=False).reset_index(drop=True)\n",
    "    return imp, base_r2\n",
    "\n",
    "# Ridge predict (log space) — keep DataFrame to preserve feature names\n",
    "def ridge_predict_log_fn(Xdf_raw):\n",
    "    Xs_df = (Xdf_raw - mu) / sigma\n",
    "    pred_log = ridge.predict(Xs_df)\n",
    "    return np.clip(pred_log, CLIP_MIN, CLIP_MAX)\n",
    "\n",
    "# NN predict (log space)\n",
    "def nn_predict_log_fn(Xdf_raw):\n",
    "    Xs = ((Xdf_raw - mu) / sigma).to_numpy().astype(np.float32)\n",
    "    return evaluate_nn_log(mlp, Xs)\n",
    "\n",
    "imp_ridge, ridge_r2log = permutation_importance_r2log(ridge_predict_log_fn, X_val, y_val_log, n_repeats=3, seed=SEED)\n",
    "print(\"Permutation importance — Baseline (Ridge) on VAL (log space)\")\n",
    "print(\"Baseline VAL R2_log:\", ridge_r2log)\n",
    "display(imp_ridge.head(20))\n",
    "\n",
    "imp_nn, nn_r2log = permutation_importance_r2log(nn_predict_log_fn, X_val, y_val_log, n_repeats=3, seed=SEED)\n",
    "print(\"Permutation importance — Neural Net on VAL (log space)\")\n",
    "print(\"NN VAL R2_log:\", nn_r2log)\n",
    "display(imp_nn.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c3c5ee",
   "metadata": {},
   "source": [
    "## Final evaluation on 50% holdout (touch once)\n",
    "Report both log-space and original-scale metrics. For rubric-style normalized comparison, compare **R²_log + MAPE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "420827db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOLDOUT — Baseline (Ridge)\n",
      "  log space:\n",
      "  RMSE_log: 0.6254690523724664\n",
      "  R2_log  : 0.38097988445067077\n",
      "  original scale:\n",
      "  RMSE: 7178.442827412152\n",
      "  MAE : 492.363648691323\n",
      "  R^2 : -0.22099133819017092\n",
      "  MAPE(%): 73.75791670847394\n",
      "\n",
      "HOLDOUT — Neural Net\n",
      "  log space:\n",
      "  RMSE_log: 0.46814532519091284\n",
      "  R2_log  : 0.6532196410745756\n",
      "  original scale:\n",
      "  RMSE: 6720.777562595433\n",
      "  MAE : 354.7781077965698\n",
      "  R^2 : -0.07026453611091776\n",
      "  MAPE(%): 38.362744179328644\n",
      "\n",
      "Normalized comparison (rubric-style):\n",
      "Baseline: R2_log = 0.38097988445067077 | MAPE% = 73.75791670847394\n",
      "NN      : R2_log = 0.6532196410745756 | MAPE% = 38.362744179328644\n"
     ]
    }
   ],
   "source": [
    "# Build holdout features ONLY here\n",
    "X_holdout = build_features(holdout_df).reindex(columns=feature_cols, fill_value=0.0)\n",
    "y_holdout = holdout_df[TARGET].to_numpy().astype(np.float64)\n",
    "y_holdout_log = np.log1p(y_holdout)\n",
    "\n",
    "X_holdout_s = (X_holdout - mu) / sigma\n",
    "\n",
    "# Baseline holdout\n",
    "hold_pred_log_ridge = ridge.predict(X_holdout_s)\n",
    "hold_pred_log_ridge = np.clip(hold_pred_log_ridge, CLIP_MIN, CLIP_MAX)\n",
    "hold_pred_ridge = safe_expm1(hold_pred_log_ridge)\n",
    "\n",
    "print(\"HOLDOUT — Baseline (Ridge)\")\n",
    "hold_base_log = report_log(y_holdout_log, hold_pred_log_ridge, \"  log space:\")\n",
    "hold_base_orig = report_orig(y_holdout, hold_pred_ridge, \"  original scale:\")\n",
    "\n",
    "# NN holdout\n",
    "hold_pred_log_nn = evaluate_nn_log(mlp, X_holdout_s.to_numpy().astype(np.float32))\n",
    "hold_pred_nn = safe_expm1(hold_pred_log_nn)\n",
    "\n",
    "print(\"\\nHOLDOUT — Neural Net\")\n",
    "hold_nn_log = report_log(y_holdout_log, hold_pred_log_nn, \"  log space:\")\n",
    "hold_nn_orig = report_orig(y_holdout, hold_pred_nn, \"  original scale:\")\n",
    "\n",
    "print(\"\\nNormalized comparison (rubric-style):\")\n",
    "print(\"Baseline: R2_log =\", hold_base_log[\"r2_log\"], \"| MAPE% =\", hold_base_orig[\"mape\"])\n",
    "print(\"NN      : R2_log =\", hold_nn_log[\"r2_log\"],   \"| MAPE% =\", hold_nn_orig[\"mape\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f66d1-ac12-41e3-84d5-76d6286f6bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
